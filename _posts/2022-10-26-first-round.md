---
layout: post
title: "按任务分类"
subtitle: ""
date: 2022-10-26
author: "夜雨声烦"
header-img: "img/bg2.png"
header-mask: 0.2
catalog: true
tags: []
---

论文阅读标识约定
*  红色：重要点
*  黄色：阅读断点
*  绿色：没读懂的

# Generation

## Captioning

1. EMScore: Evaluating Video Captioning via Coarse-Grained and Fine-Grained Embedding Matching
2. Quantifying Societal Bias Amplification in Image Captioning
3. It is Okay to Not Be Okay: Overcoming Emotional Bias in Affective Image Captioning by Contrastive Data Collection
4. Open-Domain, Content-based, Multi-modal Fact-checking of Out-of-Context Images via Online Resources
5. NOC-REK: Novel Object Captioning with Retrieved Vocabulary from External Knowledge
6. 

## Text-to-Image Generation

1. Not All Relations are Equal: Mining Informative Labels for Scene Graph Generation
2. AnyFace: Free-style Text-to-Face Synthesis and Manipulation
3. Scene Graph Expansion for Semantics-Guided Image Outpainting
4. CLIP-Forge: Towards Zero-Shot Text-to-Shape Generation
5. HairCLIP: Design Your Hair by Text and Reference Image
6. StyleT2I: Toward Compositional and High-Fidelity Text-to-Image Synthesis
7. RU-Net: Regularized Unrolling Network for Scene Graph Generation
8. Text2Mesh: Text-Driven Neural Stylization for Meshes
9. Neural Texture Extraction and Distribution for Controllable Person Image Synthesis
10. Towards Implicit Text-Guided 3D Shape Generation
11. The Devil is in the Labels: Noisy Label Correction for Robust Scene Graph Generation
12. Global Context with Discrete Diffusion in Vector Quantised Modelling for Image Generation
13. LAFITE : Towards Language-Free Training for Text-to-Image Generation
14. CLIPstyler: Image Style Transfer with a Single Text Condition
15. ManiTrans: Entity-Level Text-Guided Image Manipulation via Token-wise Semantic Alignment and Generation
16. 3D-aware Image Synthesis via Learning Structural and Textural Representations
17. 

# Understanding

## Visual Question and Answer

1. ScanQA: 3D Question Answering for Spatial Scene Understanding
2. Grounding Answers for Visual Questions Asked by Visually Impaired People
3. Measuring Compositional Consistency for Video Question Answering
4. From Representation to Reasoning: Towards both Evidence and Commonsense Reasoning for Video Question-Answering
5. WebQA: Multihop and Multimodal QA
6. V-Doc : Visual questions answers with Documents
7. Dual-Key Multimodal Backdoors for Visual Question Answering
8. SwapMix: Diagnosing and Regularizing the Over-Reliance on Visual Context in Visual Question Answering
9. LaTr: Layout-Aware Transformer for Scene-Text VQA
10. 


## Visual Reasoning
1. Self-Supervised Material and Texture Representation Learning for Remote Sensing Tasks
2. REX: Reasoning-aware and Grounded Explanation
3. 3MASSIV: Multilingual, Multimodal and Multi-Aspect dataset of Social Media Short Videos
4. A Simple Multi-Modality Transfer Learning Baseline for Sign Language Translation
5. 


## Natural Language Explanations

1. NLX-GPT: A Model for Natural Language Explanations in Vision and Vision-Language Tasks
2. 

# Retrieval

## Image-text Retrieval

1. Pushing the Performance Limit of Scene Text Recognizer without Human Annotation
2. Towards End-to-End Unified Scene Text Detection and Layout Analysis
3. Open-Set Text Recognition via Character-Context Decoupling
4. Learning Program Representations for Food Images and Cooking Recipes
5. Cross Modal Retrieval with Querybank Normalisation
6. Towards Weakly-Supervised Text Spotting using a Multi-Task Transformer
7. GEN-VLKT: Simplify Association and Enhance Interaction Understanding for HOI Detection
8. Disentangling visual and written concepts in CLIP
9. 

## Text-image Retrieval
1. LAVT: Language-Aware Vision Transformer for Referring Image Segmentation
2. Cross Language Image Matching for Weakly Supervised Semantic Segmentation
3. Sign Language Video Retrieval with Free-Form Textual Queries
4. Modeling Motion with Multi-Modal Features for Text-Based Video Segmentation
5. Language as Queries for Referring Video Object Segmentation
6. Language-Bridged Spatial-Temporal Interaction for Referring Video Object Segmentation
7. 

# Grounding

1. One Step at a Time: Long-Horizon Vision-and-Language Navigation with Milestones
2. 3D-SPS: Single-Stage 3D Visual Grounding via Referred Point Progressive Selection
3. MAD: A Scalable Dataset for Language Grounding in Videos from Movie Audio Descriptions
4. Less is More: Generating Grounded Navigation Instructions from Landmarks
5. ENVEDIT: Environment Editing for Vision-and-Language Navigation
6. Compositional Temporal Grounding with Structured Variational Cross-Graph Correspondence Learning
7. Shifting More Attention to Visual Backbone: Query-modulated Refinement Networks for End-to-End Visual Grounding
8. Text2Pos: Text-to-Point-Cloud Cross-Modal Localization
9. Reinforced Structured State-Evolution for Vision-Language Navigation
10. TubeDETR: Spatio-Temporal Video Grounding with Transformers
11. HOP: History-and-Order Aware Pre-training for Vision-and-Language Navigation
12. ADAPT: Vision-Language Navigation with Modality-Aligned Action Prompts
13. Improving Visual Grounding with Visual-Linguistic Verification and Iterative Reasoning
14. Bridging the Gap Between Learning in Discrete and Continuous Environments for Vision-and-Language Navigation
15. Multi-View Transformer for 3D Visual Grounding
16. Cross-modal Map Learning for Vision and Language Navigation
17. Think Global, Act Local: Dual-scale Graph Transformer for Vision-and-Language Navigation
18. 

# Unknown

1. Explaining Deep Convolutional Neural Networks via Latent Visual-Semantic Filter Attention
2. P3IV: Probabilistic Procedure Planning from Instructional Videos with Weak Supervision
3. Are Multimodal Transformers Robust to Missing Modality?
4. Signing at Scale: Learning to Co-Articulate Signs for Large-Scale Photo-Realistic Sign Language Production
5. Audio-visual Generalised Zero-shot Learning with Cross-modal Attention and Language
6. VL-InterpreT: An Interactive Visualization Tool for Interpreting Vision-Language Transformers
7. Robust Cross-Modal Representation Learning with Progressive Self-Distillation
8. CLIP-NeRF: Text-and-Image Driven Manipulation of Neural Radiance Fields
9. Unsupervised Vision-and-Language Pre-training via Retrieval-based Multi-Granular Alignment
10. Video-Text Representation Learning via Differentiable Weak Temporal Alignment
11. Habitat-Web: Learning Embodied Object-Search Strategies from Human Demonstrations at Scale
12. On Guiding Visual Attention with Language Specification
13. 


78